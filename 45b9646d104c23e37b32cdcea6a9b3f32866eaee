{
  "comments": [
    {
      "key": {
        "uuid": "c45f7ced_b090ec32",
        "filename": "files/openstack-cli-server/openstack-cli-server",
        "patchSetId": 21
      },
      "lineNbr": 66,
      "author": {
        "id": 4393
      },
      "writtenOn": "2021-02-10T19:41:44Z",
      "side": 1,
      "message": "So I think this will end up serializing all the would-be-parallel osc commands that I run in parallel right? Maybe that won\u0027t matter if the startup overhead is nearly zero, but I\u0027m pretty sure we\u0027re overlapping more than just startup time right now based on my seat-of-the-pants feelings. Not just OSC overhead, but also waiting on slow replies from servers. Parallelizing the execution of those not only helps with OSC overhead, but also latency due to slowness in the servers.\n\nPresumably we could just use a queue in here to fork off some workers and let one handle each accept? Not sure how much complexity you want to build into a server written in devstack to speed up a slow python program, but I also don\u0027t want to lose the benefit we get by doing things like flavor and volume type creation in parallel.",
      "revId": "45b9646d104c23e37b32cdcea6a9b3f32866eaee",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": true
    }
  ]
}